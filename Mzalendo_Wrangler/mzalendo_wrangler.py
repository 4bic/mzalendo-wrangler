# -*- coding: utf-8 -*-
"""mzalendo_ke_legislators_wrangler.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1StqIsPZWsh_ZPs9NJV40u3AczEg-sNYi

# Set up Essentials
"""

from google.colab import drive , files
import os, os.path
import pandas as pd
from pandas.io.json import json_normalize
import json
import requests
import numpy as np

"""## **Mount Drive and Operate from within said folder**"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/'My Drive'/Colab_Notebooks/mzalendo

persons = "http://info.mzalendo.com/media_root/popolo_json/persons.json"
organization = "http://info.mzalendo.com/media_root/popolo_json/organizations.json"
memberships = "http://info.mzalendo.com/media_root/popolo_json/memberships.json"
pombola = "http://info.mzalendo.com/media_root/popolo_json/memberships.json"
candidates = "https://docs.google.com/spreadsheets/d/e/2PACX-1vTR3hgRnOrPi6Opkr3Z622_onNYEtzds51TxqS1-VBEcDqP8O0nLjr1XwRkQYCGLrusNL6nJLyxtQbe/pub?gid=671749755&single=true&output=csv"
elected = "https://docs.google.com/spreadsheets/d/e/2PACX-1vTR3hgRnOrPi6Opkr3Z622_onNYEtzds51TxqS1-VBEcDqP8O0nLjr1XwRkQYCGLrusNL6nJLyxtQbe/pub?gid=655626479&single=true&output=csv"

"""## Work from file with nested jsons'"""

with open(pombola) as data_file:
    data = json.load(data_file)

# data = json_normalize("pombola.json")

df = json_normalize(data)

"""## Collect All Candidates data"""

all = pd.read_csv(candidates)
elected = pd.read_csv(elected)

all.head(3)

"""## Isolate Elected legislators"""

all['elected'] = np.where(all['name'].isin(elected['name'].str.upper()),"elected-2017", "not-elected")

# all.to_csv("./ke_legislators.csv")



"""# Persons Section

Access the json file
"""

data_p = pd.read_json(persons)
p_columns = ['id', 'name','contact_details', 'images', 'birth_date', 'gender', 'death_date',
             'summary', 'email', 'biography', 'national_identity']

data_p = data_p[p_columns]


"""Clean up *id* and *images*  columns"""

def clean_id(x):
  if pd.notnull(x):
    id = x.split(":")[1]
    return id

def get_img_url(x):
  if pd.notnull(x):
    url = x[0].get('url')
    return url

"""get emails from contacts columns"""

def get_email(x):
  for i in x:
    contacts_type = i.get('type')
    if contacts_type == "email":
      email = i.get('value')
      return email

def get_phone(x):
  for i in x:
    contacts_type = i.get('type')
    if contacts_type == "phone":
      phone = i.get('value')
      return phone

def get_address(x):
  for i in x:
    contacts_type = i.get('type')
    if contacts_type == "address":
      address = i.get('value')
      return address

# save to local Drive
# data_p.to_csv('ke_persons.csv')

# Access the ID's only
data_p['id'] = data_p['id'].apply(lambda x: clean_id(x))
# get url from dictionary
data_p['images'] = data_p['images'].apply(lambda x: get_img_url(x))
# add email
data_p['email'] = data_p['contact_details'].apply(lambda x: get_email(x)  )
# add phone no.'s
data_p['phone'] = data_p['contact_details'].apply(lambda x: get_phone(x)  )



"""# Organizations Section"""

data_org = pd.read_json(organization)
org_columns = ['id','name', 'category', 'classification','contact_details',
               'founding_date', 'dissolution_date']
data_org = data_org[org_columns]

"""Clean columns"""

# Access the ID's only
data_org['id'] = data_org['id'].apply(lambda x: clean_id(x))
# add email
data_org['email'] = data_org['contact_details'].apply(lambda x: get_email(x)  )
# add phone no.'s
data_org['phone'] = data_org['contact_details'].apply(lambda x: get_phone(x)  )
# add addreses
data_org['address'] = data_org['contact_details'].apply(lambda x: get_address(x)  )

# save to local Drive
# data_org.to_csv('KE_mzalendo_organizations.csv')



"""# Memberships"""

data_mb = pd.read_json(memberships)
# clean Pos ID's
data_mb['id'] = data_mb['id'].apply(lambda x: clean_id(x))
# org ID
data_mb['organization_id'] = data_mb['organization_id'].apply(lambda x: clean_id(x))
# person's ID
data_mb['person_id'] = data_mb['person_id'].apply(lambda x: clean_id(x))

mb_columns = ['id','organization_id','person_id','role','area',
                   'end_date','start_date','identifiers','legislative_period_id']

data_mb = data_mb[mb_columns]

"""Define Memberships regions by 'Name' and 'Region-Type'"""

def get_region(x):
  if pd.notnull(x):
    region = x['name']
    return region

def get_area_type(x):
  if pd.notnull(x):
    area_type = x['area_type']
    return area_type

def get_term(x):
  if pd.notnull(x) and 'session' in x.keys():
    for i in x['session']:
      if i == 'slug':
        term = x['session'].get('slug')
        return term



"""Add the Regional data fields to dataset"""

# map abbreviations to region name
area_types = {'CON': 'Constituency', 'DIS': 'District', 'PRO': 'Province', 'CTR':'Country'}
# Region of org / menber
data_mb['region'] = data_mb['area'].apply(lambda x: get_region(x))
# area type
data_mb['area_type'] = data_mb['area'].apply(lambda x: get_area_type(x)).map(area_types)
# person's term
data_mb['term'] = data_mb['area'].apply(lambda x: get_term(x))

# save to local drive

# data_mb.to_csv('ke_mzalendo_memberships.csv')
