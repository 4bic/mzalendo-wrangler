{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gh_stats_population_scrape.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QK3k58O-tTl",
        "colab_type": "code",
        "outputId": "02fe3e98-fb52-4448-d178-304e326dfd84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd \"/content/drive/My Drive/Colab_Notebooks/ghana_pop\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab_Notebooks/ghana_pop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8bYUQU4_O2h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup as BS\n",
        "import requests\n",
        "import pandas as pd \n",
        "import os\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ3HEM54_Tdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_url = \"https://www.statsghana.gov.gh/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tUotNVhAT6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = requests.get(base_url)\n",
        "c = r.content\n",
        "soup = BS(c, \"html.parser\")\n",
        "# check source code of loaded page\n",
        "\n",
        "# # extract regional links\n",
        "all = soup.find_all(\"g\") #.get('href')\n",
        "all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxhf_4NiQdof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "region_links = []\n",
        "for x in all:\n",
        "  # extract link and clean\n",
        "  link = x.find('a').get('href').replace(\"®\",\"&reg\")\n",
        "  region_links.append(link)\n",
        "  # print(x.find('a').get('href'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVjzfCefQRo5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# collect page contents for each region:\n",
        "for link in region_links:\n",
        "  url = base_url + link\n",
        "  print (url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gibG_HqXxh5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reg_2 = \"https://www.statsghana.gov.gh/regionalpopulation.php?population=MTMxOTU3MTAxOC44MjU=&&Bono&regid=2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCldnndktEbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = requests.get(reg_2)\n",
        "c = r.content\n",
        "soup = BS(c, \"html.parser\")\n",
        "# check source code of loaded page\n",
        "# # extract regional links\n",
        "\n",
        "region_name = soup.find('div',{'class' :'graphWrap'}).find('h2').text #.get('href')\n",
        "# len(all)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfNzF1z5CiRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab table and details\n",
        "reg_2table = pd.read_html(reg_2, attrs = {'class':'TDownloadDoc'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dirlc_ZyYgKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K = reg_2table[0][('Year', 'District Name')]\n",
        "V = reg_2table[0][('Population',    'Population')]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLRxY9hJdmRZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reG = pd.DataFrame(zip(K, V)).dropna()\n",
        "reG.columns = ['district','population']\n",
        "# clean up\n",
        "reG['district'][0] = region_name + str(' REGION')\n",
        "reG.drop(2,axis=0)\n",
        "reG\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8Exh682EMrx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for reg_url in extract_links(all):\n",
        "    region_name = gather_region_name(reg_url)\n",
        "    # return reg_table\n",
        "    region_data = pd.read_html(reg_url, attrs = {'class':'TDownloadDoc'})\n",
        "    K = region_data[0][('Year', 'District Name')]\n",
        "    V = region_data[0][('Population',    'Population')]\n",
        "    reg_df = pd.DataFrame(zip(K, V)).dropna()\n",
        "    reg_df.columns = ['district','population']\n",
        "    reg_df['district'][0] = region_name + str(' REGION')\n",
        "    # # clean up\n",
        "    reg_df = reg_df.drop(2,axis=0)\n",
        "    # print(reg_df)\n",
        "    GH_pop = pd.concat([GH_pop,reg_df],ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt0rG2eW4NCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gather_page_all(url,element):\n",
        "  r = requests.get(url)\n",
        "  c = r.content\n",
        "  soup = BS(c, \"html.parser\")\n",
        "# check source code of loaded page\n",
        "  all = soup.find_all(element) #.get('href')\n",
        "  return all\n",
        "\n",
        "def gather_region_name(reg_url):\n",
        "  r = requests.get(reg_url)\n",
        "  c = r.content\n",
        "  soup = BS(c, \"html.parser\")\n",
        "# check source code of loaded page\n",
        "  region_name = soup.find('div',{'class' :'graphWrap'}).find('h2').text\n",
        "  return region_name\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxOIi5jh4Sjo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_links(all):\n",
        "  region_links = []\n",
        "  for item in all:\n",
        "    # extract link and clean\n",
        "    href = item.find('a').get('href').replace(\"®\",\"&reg\")\n",
        "    link = base_url + href\n",
        "    # print (link)\n",
        "    region_links.append(link)\n",
        "  return region_links \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7snZQ0dBmn7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_page_details():\n",
        "  GH_pop = pd.DataFrame()\n",
        "  for reg_url in extract_links(all):\n",
        "      region_name = gather_region_name(reg_url)\n",
        "      # return reg_table\n",
        "      region_data = pd.read_html(reg_url, attrs = {'class':'TDownloadDoc'})\n",
        "      K = region_data[0][('Year', 'District Name')]\n",
        "      V = region_data[0][('Population',    'Population')]\n",
        "      reg_df = pd.DataFrame(zip(K, V)).dropna()\n",
        "      reg_df.columns = ['district','population']\n",
        "      reg_df['district'][0] = region_name + str(' REGION')\n",
        "      # # clean up\n",
        "      reg_df = reg_df.drop(2,axis=0)\n",
        "      # print(reg_df)\n",
        "      GH_pop = pd.concat([GH_pop,reg_df],ignore_index=True)\n",
        "  GH_pop.to_csv('gh_pop.csv')\n",
        "  return GH_pop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRvQe6nUwb-U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "  gather_page_all(base_url,\"g\")\n",
        "  extract_links(all)\n",
        "  collect_page_details()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  base_url = \"https://www.statsghana.gov.gh/\"\n",
        "  main()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}